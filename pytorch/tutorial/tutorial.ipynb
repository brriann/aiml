{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e1c281-a523-47d2-bdc5-91e9aa1a94fb",
   "metadata": {},
   "source": [
    "# https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84233d89-1a82-4c12-bb6e-2d6e793d5608",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f1272a7-e46f-474d-b863-80bfade90e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6385e04a-9f8d-4ff8-9131-96815baa5872",
   "metadata": {},
   "source": [
    "### Tensor Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113405c7-9886-4631-896c-e9112d489bb1",
   "metadata": {},
   "source": [
    "Tensors are a data structure similar to arrays and matrices.\n",
    "Tensors encode the inputs and outputs of a model, and the model's parameters.\n",
    "Tensors are similar to numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5024292-42b2-43f2-97c6-8b2e95e14b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors can be created directly from data - the data type is inferred.\n",
    "data = [[1, 2], [3,4 ]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc668817-33c0-4f5c-a8cd-aba589c94f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors can be created from a numpy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17a6b246-2d69-412b-afec-681b61c51cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.0593, 0.5889],\n",
      "        [0.4823, 0.6593]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tensors can be created from another tensor\n",
    "# properties like shape/datatype are retained unless overridden\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab494656-672d-4ee3-a933-cfc324691852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.9500, 0.0427, 0.8385],\n",
      "        [0.5752, 0.1868, 0.8477]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# tensors can be created from a tuple of dimensions\n",
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b83e346-80af-4c1e-b259-37b48bc8fb67",
   "metadata": {},
   "source": [
    "### Tensor Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba6135f-f1c7-4907-96f9-25e17796bb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# tensor attributes describe shape, datatype, and device on which they're stored\n",
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165e8d3-e7b0-405e-999f-64a652ef894b",
   "metadata": {},
   "source": [
    "### Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59de5b-0bb1-43fa-b876-32970eec8f9f",
   "metadata": {},
   "source": [
    "Tensor operations include transpose, index, slice, mathematical operations, linear algebra,\n",
    "random sampling, etc...\n",
    "\n",
    "See: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e30e8ac-3e29-4673-a535-4a5263ddfd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: False\n"
     ]
    }
   ],
   "source": [
    "# move a tensor to the GPU, if available\n",
    "print(f\"GPU is available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5356214-259c-4ea5-9262-ddef1768772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2006b5a-1387-43c9-855f-409ae889100c",
   "metadata": {},
   "source": [
    "EXAMPLE TENSOR OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cffb299-dcfb-42f8-81ac-0e045c3a2799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# numpy-like indexing and slicing\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "949e14cd-8559-4ef6-b547-2c6d74b647c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# joining tensors\n",
    "# concatenate a sequence of tensors along a given dimension\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3250d462-9fac-470e-b270-9cc5c3bdaca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "# concatenate a sequence of tensors along a new dimension\n",
    "t2 = torch.stack([tensor, tensor, tensor])\n",
    "print(t2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dabdb86e-f326-403b-8762-27801add9f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# multiplying tensors\n",
    "# computes the element-wise product\n",
    "print(tensor)\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c33b61fd-7548-4f71-b64f-2e7c9e33e98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication between tensors\n",
    "print(tensor)\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733ed0b5-8f2c-406e-aa25-146afc53cac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in-place operations have a _suffix.\n",
    "# they can save memory, but cause a loss of history, which affects computing derivatives\n",
    "# NOT RECOMMENDED\n",
    "\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce471c9-7c41-46b4-a4c3-f50fcaa5f725",
   "metadata": {},
   "source": [
    "### Bridge with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24dbd6-505e-41e6-8e0d-bc911d35d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors on CPU and NumPy arrays can share underlying memory locations\n",
    "# (changing one will change the other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e641d48-d965-48b6-859c-e67be4673e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# tensor to numpy array\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec9611fb-637a-40fd-ae43-f70ba0c86d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# change in tensor is reflected in numpy array\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1217176-2ec6-47bb-9586-9e483c9d81c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy array to tensor\n",
    "n = np.ones(5)\n",
    "print(f\"n: {n}\")\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"t: {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fa9a419-ded8-43af-b7cd-aae1d2f99dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# changes in numpy array are reflected in tensor\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e961f-b00e-481e-b7b2-fa65fe6aa633",
   "metadata": {},
   "source": [
    "# torch.autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ba0e5-380a-4a4b-b4b1-e8faee0dba6f",
   "metadata": {},
   "source": [
    "torch.autograd = automatic differentiation engine that powers neural network (NN) training.\n",
    "\n",
    "## background \n",
    "\n",
    "- NN's are a collection of nested functions that are executed on some input data.\n",
    "- functions are defined by PARAMETERS (weights and biases), which pytorch stores in tensors\n",
    "\n",
    "### two steps to training NN:\n",
    "\n",
    "1. forward propagation - In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.\n",
    "\n",
    "2. backward propagation - In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the functions (gradients), and optimizing the parameters using gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d7482-3c14-4a91-b87b-45b5645db394",
   "metadata": {},
   "source": [
    "## usage in pytorch\n",
    "\n",
    "For this example, we load a pretrained resnet18 model from torchvision. We create a random data tensor to represent a single image with 3 channels, and height & width of 64, and its corresponding label initialized to some random values. Label in pretrained models has shape (1,1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8fcd2b8-cc82-484c-a718-4bd7b6b9574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/brianfoster/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# disable SSL verification to download model\n",
    "# https://stackoverflow.com/questions/71263622/sslcertverificationerror-when-downloading-pytorch-datasets-via-torchvision\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3596bbf0-bf74-4a09-ab8d-acc296d34a11",
   "metadata": {},
   "source": [
    "Next, we run the input data through the model through each of its layers to make a prediction. This is the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b38cf9-9a82-4da5-b850-1723378839a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(data) # forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b81a22-3a25-4207-aba5-216078e4f358",
   "metadata": {},
   "source": [
    "We use the model’s prediction and the corresponding label to calculate the error (loss). \n",
    "The next step is to backpropagate this error through the network. \n",
    "Backward propagation is kicked off when we call .backward() on the error tensor. \n",
    "Autograd then calculates and stores the gradients for each model parameter in the parameter’s .grad attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b65891-922c-419d-a930-2566635bc2e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loss \u001b[38;5;241m=\u001b[39m (prediction \u001b[38;5;241m-\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/_venvs/torch/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/_venvs/torch/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward() # backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eae45e-1a5c-46aa-8e98-eb0356004cb8",
   "metadata": {},
   "source": [
    "Next, we load an optimizer, in this case SGD with a learning rate of 0.01 and momentum of 0.9. We register all the parameters of the model in the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "348ba16e-dfa7-485a-b0c9-2d4257d4a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79677c47-7dd3-45fc-82c8-d79c7408ef4c",
   "metadata": {},
   "source": [
    "Finally, we call .step() to initiate gradient descent. The optimizer adjusts each parameter by its gradient stored in .grad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dbc9869-b7b6-4b3c-b71f-9b7d7b6b6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step() #gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da9bc4-c5bd-40e8-9356-381abec746b5",
   "metadata": {},
   "source": [
    "## differentiation in autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a3814-0411-4b09-bf5e-08a88b629e43",
   "metadata": {},
   "source": [
    "Let’s take a look at how autograd collects gradients. We create two tensors a and b with requires_grad=True. This signals to autograd that every operation on them should be tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf60408-89b2-497c-a939-94a0c5efffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
